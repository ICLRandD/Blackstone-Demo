import streamlit as st
import spacy
from spacy import displacy
import blackstone
from blackstone.pipeline.sentence_segmenter import SentenceSegmenter
from blackstone.displacy_palette import ner_displacy_options
from blackstone.rules import CITATION_PATTERNS
import pandas as pd 
import altair as alt


SPACY_MODEL_NAMES = ["en_blackstone_proto",]
DEFAULT_TEXT = "In R v Horncastle [2009] 1 AC 373, the Supreme Court held that s 114 of the Criminal Justice Act 2003 was incompatible with Article 6 of the European Convention on Human Rights."
HTML_WRAPPER = """<div style="overflow-x: auto; border: 1px solid #e6e9ef; border-radius: 0.25rem; padding: 1rem; margin-bottom: 2.5rem">{}</div>"""

@st.cache(allow_output_mutation=True)
def load_model(name):
    nlp = spacy.load(name)
    sentence_segmenter = SentenceSegmenter(nlp.vocab, CITATION_PATTERNS)
    nlp.add_pipe(sentence_segmenter, before="parser")
    return nlp

@st.cache(allow_output_mutation=True)
def process_text(model_name, text):
    nlp = load_model(model_name)
    return nlp(text)

def get_top_cat(doc):
    """
    Function to identify the highest scoring category
    prediction generated by the textcat pipe. 
    """
    cats = doc.cats
    max_score = max(cats.values()) 
    max_cats = [k for k, v in cats.items() if v == max_score]
    max_cat = max_cats[0]
    return (max_cat, max_score)


st.sidebar.markdown('<img src="https://iclr.s3-eu-west-1.amazonaws.com/assets/iclrand/blackstone_seal.svg" alt="Blackstone_Logo" />', unsafe_allow_html=True)

spacy_model = st.sidebar.selectbox("Model name", SPACY_MODEL_NAMES)
model_load_state = st.info(f"Loading model '{spacy_model}'...")
nlp = load_model(spacy_model)
model_load_state.empty()

text = st.text_area("Text to analyze", DEFAULT_TEXT)
doc = process_text(spacy_model, text)

if "ner" in nlp.pipe_names:
    st.header("Named Entities")
    st.sidebar.header("Named Entities")
    default_labels = ["CASENAME", "CITATION", "INSTRUMENT", "PROVISION", "COURT", "JUDGE"]
    labels = st.sidebar.multiselect(
        "Entity labels", nlp.get_pipe("ner").labels, default_labels
    )
    html = displacy.render(doc, style="ent", options=ner_displacy_options)
    # Newlines seem to mess with the rendering
    html = html.replace("\n", " ")
    st.write(HTML_WRAPPER.format(html), unsafe_allow_html=True)
    attrs = ["text", "label_", "start", "end", "start_char", "end_char"]
    data = [
        [str(getattr(ent, attr)) for attr in attrs]
        for ent in doc.ents
        if ent.label_ in labels
    ]

    df = pd.DataFrame(data, columns=attrs)
    st.dataframe(df)
    CASENAMES = len([ent.text for ent in doc.ents if ent.label_ == "CASENAME"])
    CITATIONS = len([ent.text for ent in doc.ents if ent.label_ == "CITATION"])
    INSTRUMENTS = len([ent.text for ent in doc.ents if ent.label_ == "INSTRUMENT"])
    PROVISIONS = len([ent.text for ent in doc.ents if ent.label_ == "PROVISION"])
    COURTS = len([ent.text for ent in doc.ents if ent.label_ == "COURT"])
    JUDGES = len([ent.text for ent in doc.ents if ent.label_ == "JUDGE"])

    entity_data = {"entities": ["Casenames", "Citations", "Instruments", "Provisions", "Courts", "Judges"], "counts":[CASENAMES, CITATIONS, INSTRUMENTS, PROVISIONS, COURTS, JUDGES] }
    entity_df = pd.DataFrame(entity_data)

    entity_chart = alt.Chart(entity_df).mark_bar().encode(
    x='entities:N',
    y='counts:Q',
    color='entities'
    )

    st.altair_chart(entity_chart, width=900)



if "textcat" in nlp.pipe_names:
    st.header("Text Categoriser")
    st.sidebar.header("Text Categoriser")
    include_uncat = st.sidebar.checkbox("Include uncategorised sentences?")
    TOP_CATEGORIES = []
    SCORES = []
    SENTENCES = []
    sentences = [sent.text for sent in doc.sents]
    for i, doc in enumerate(nlp.pipe(sentences)):
        top_category = get_top_cat(doc)
        if include_uncat:
            TOP_CATEGORIES.append(top_category[0])
            SCORES.append(top_category[1])
            SENTENCES.append(doc)
        else:
            if "UNCAT" not in str(top_category[0]):
                TOP_CATEGORIES.append(top_category[0])
                SCORES.append(top_category[1])
                SENTENCES.append(doc)
    category_data = {"Sentence": SENTENCES, "Category": TOP_CATEGORIES, "Score": SCORES}
    category_df = pd.DataFrame(category_data)
    st.table(category_df)


    st.sidebar.markdown("## Acknowledgements")
    st.sidebar.markdown("Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.")

    st.sidebar.markdown('<img src="https://iclr.s3-eu-west-1.amazonaws.com/assets/iclrand/sitecode.svg" alt="Blackstone_Logo" />', unsafe_allow_html=True)